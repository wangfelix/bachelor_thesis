{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T19:29:46.565955Z",
     "start_time": "2025-03-17T19:29:46.548746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, KMeansSMOTE"
   ],
   "id": "55b421877493f0e9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T19:29:46.581156Z",
     "start_time": "2025-03-17T19:29:46.568508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a custom colormap\n",
    "colors = [\n",
    "    (0.945, 0.980, 0.733),  # light yellow-green\n",
    "    (0.263, 0.671, 0.702),  # teal\n",
    "    (0.137, 0.294, 0.620),  # navy blue\n",
    "]\n",
    "\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom_diverging\", colors, N=256)\n",
    "\n",
    "# Custom formatter for correlation values\n",
    "def custom_fmt(val):\n",
    "    abs_val = abs(val)\n",
    "    if abs_val == 1.0:\n",
    "        return \"1.0\"\n",
    "    else:\n",
    "        return f\".{int(abs_val * 100):02d}\"\n",
    "\n",
    "# Function to create and save correlation heatmap\n",
    "def plot_correlation_heatmap(df, title, filename):\n",
    "    # Drop the target variable for correlation calculation\n",
    "    if 'performance_class' in df.columns:\n",
    "        data = df.drop(columns=[\"performance_class\"])\n",
    "    else:\n",
    "        data = df\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = data.corr()\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    \n",
    "    # Create heatmap\n",
    "    heatmap = sns.heatmap(\n",
    "        corr_matrix,\n",
    "        mask=np.triu(np.ones_like(corr_matrix, dtype=bool), k=1),\n",
    "        annot=True,\n",
    "        fmt=\"\",\n",
    "        annot_kws={\"size\": 8},\n",
    "        cmap=custom_cmap,\n",
    "        vmin=-1, vmax=1,\n",
    "        center=0,\n",
    "        linewidths=0.2,\n",
    "        cbar_kws={\"shrink\": 0.8}\n",
    "    )\n",
    "    \n",
    "    # Apply custom formatter\n",
    "    for text in heatmap.texts:\n",
    "        text_value = float(text.get_text().replace('−', '-'))\n",
    "        text.set_text(custom_fmt(text_value))\n",
    "    \n",
    "    # Add title\n",
    "    plt.title(title, fontsize=14)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(bottom=0.3)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    return corr_matrix\n",
    "\n",
    "# Function to calculate correlation difference metrics\n",
    "def calculate_correlation_difference(original_corr, augmented_corr):\n",
    "    # Calculate absolute differences\n",
    "    diff_matrix = np.abs(original_corr - augmented_corr)\n",
    "    \n",
    "    # Calculate mean absolute difference (excluding diagonal)\n",
    "    mask = ~np.eye(original_corr.shape[0], dtype=bool)\n",
    "    mean_abs_diff = diff_matrix.values[mask].mean()\n",
    "    \n",
    "    # Calculate max absolute difference\n",
    "    max_abs_diff = diff_matrix.values[mask].max()\n",
    "    \n",
    "    return {\n",
    "        'mean_abs_diff': mean_abs_diff,\n",
    "        'max_abs_diff': max_abs_diff,\n",
    "        'diff_matrix': diff_matrix\n",
    "    }\n",
    "\n",
    "# Function to plot feature distributions\n",
    "def plot_feature_distributions(original_df, augmented_df, method_name):\n",
    "    if 'performance_class' in original_df.columns:\n",
    "        original_features = original_df.drop(columns=['performance_class'])\n",
    "        augmented_features = augmented_df.drop(columns=['performance_class'])\n",
    "    else:\n",
    "        original_features = original_df\n",
    "        augmented_features = augmented_df\n",
    "    \n",
    "    # Select a subset of features if there are too many\n",
    "    features_to_plot = original_features.columns[:min(10, len(original_features.columns))]\n",
    "    \n",
    "    fig, axes = plt.subplots(len(features_to_plot), 2, figsize=(15, 4*len(features_to_plot)))\n",
    "    \n",
    "    for i, feature in enumerate(features_to_plot):\n",
    "        # Original data distribution\n",
    "        sns.histplot(original_features[feature], kde=True, color='royalblue', ax=axes[i, 0])\n",
    "        axes[i, 0].set_title(f\"{feature} (Original)\")\n",
    "        \n",
    "        # Augmented data distribution\n",
    "        sns.histplot(augmented_features[feature], kde=True, color='orange', ax=axes[i, 1])\n",
    "        axes[i, 1].set_title(f\"{feature} ({method_name})\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../data/figures/feature_distributions_{method_name}.pdf\", dpi=300)\n",
    "    plt.close()"
   ],
   "id": "ce353bcffb6520b1",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-17T19:30:00.230489Z",
     "start_time": "2025-03-17T19:29:46.582281Z"
    }
   },
   "source": [
    "# Main function to run the augmentation experiment\n",
    "def run_augmentation_experiment(input_file):\n",
    "    # Load dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv(input_file)\n",
    "    X = df.drop(columns=[\"performance_class\"])\n",
    "    y = df[\"performance_class\"]\n",
    "    \n",
    "    # Save original correlation matrix\n",
    "    original_corr = plot_correlation_heatmap(\n",
    "        X, \n",
    "        \"Original Feature Correlation Matrix\", \n",
    "        \"../data/figures/original_feature_correlation_heatmap.pdf\"\n",
    "    )\n",
    "    \n",
    "    # Define augmentation methods\n",
    "    augmentation_methods = {\n",
    "        \n",
    "        'SMOTE_k5': SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=42),\n",
    "        'BorderlineSMOTE': BorderlineSMOTE(sampling_strategy='auto', random_state=42),\n",
    "        'KMeansSMOTE': KMeansSMOTE(sampling_strategy='auto', cluster_balance_threshold=0.1, random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    augmented_dfs = {}\n",
    "    \n",
    "    # Run each augmentation method\n",
    "    for method_name, augmenter in augmentation_methods.items():\n",
    "        print(f\"\\nRunning {method_name}...\")\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Initial augmentation to balance classes\n",
    "            X_resampled_1, y_resampled_1 = augmenter.fit_resample(X, y)\n",
    "            df_balanced = pd.DataFrame(X_resampled_1, columns=X.columns)\n",
    "            df_balanced[\"performance_class\"] = y_resampled_1\n",
    "                        \n",
    "            print(f\"Dataset size after initial {method_name}:\", df_balanced.shape)\n",
    "            print(y_resampled_1.value_counts())\n",
    "                        \n",
    "            # Direct large-scale augmentation to reach target size\n",
    "            target_count_per_class = 5000\n",
    "            sampling_strategy_large = {}\n",
    "            for cls in y_resampled_1.unique():\n",
    "                sampling_strategy_large[cls] = target_count_per_class\n",
    "                        \n",
    "            augmenter_params = {}\n",
    "            if method_name == 'KMeansSMOTE':\n",
    "                augmenter_params['cluster_balance_threshold'] = 0.1\n",
    "                        \n",
    "            if method_name == 'SMOTE_k5':\n",
    "                augmenter_large = SMOTE(sampling_strategy=sampling_strategy_large, k_neighbors=5, random_state=44, **augmenter_params)\n",
    "            elif method_name == 'BorderlineSMOTE':\n",
    "                augmenter_large = BorderlineSMOTE(sampling_strategy=sampling_strategy_large, random_state=44, **augmenter_params)\n",
    "            elif method_name == 'KMeansSMOTE':\n",
    "                augmenter_large = KMeansSMOTE(sampling_strategy=sampling_strategy_large, random_state=44, **augmenter_params)\n",
    "                        \n",
    "            X_balanced = df_balanced.drop(columns=[\"performance_class\"])\n",
    "            y_balanced = df_balanced[\"performance_class\"]\n",
    "            X_resampled_large, y_resampled_large = augmenter_large.fit_resample(X_balanced, y_balanced)\n",
    "                        \n",
    "            df_large = pd.DataFrame(X_resampled_large, columns=X.columns)\n",
    "            df_large[\"performance_class\"] = y_resampled_large\n",
    "                        \n",
    "            print(f\"Large dataset size after {method_name}:\", df_large.shape)\n",
    "            print(y_resampled_large.value_counts())\n",
    "                        \n",
    "            # Save the augmented correlation matrix\n",
    "            augmented_corr = plot_correlation_heatmap(\n",
    "                df_large,\n",
    "                f\"{method_name} Augmented Feature Correlation Matrix\",\n",
    "                f\"../data/figures/{method_name}_correlation_heatmap.pdf\"\n",
    "            )\n",
    "                        \n",
    "            # Calculate correlation difference metrics\n",
    "            diff_results = calculate_correlation_difference(original_corr, augmented_corr)\n",
    "                        \n",
    "            # Save results\n",
    "            results[method_name] = diff_results\n",
    "            augmented_dfs[method_name] = df_large\n",
    "                        \n",
    "            # Plot the difference matrix\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            heatmap = sns.heatmap(\n",
    "                diff_results['diff_matrix'],\n",
    "                mask=np.triu(np.ones_like(diff_results['diff_matrix'], dtype=bool), k=1),\n",
    "                annot=True,\n",
    "                fmt=\"\",\n",
    "                annot_kws={\"size\": 8},\n",
    "                cmap=custom_cmap,\n",
    "                vmin=0,\n",
    "                vmax=0.5\n",
    "            )\n",
    "            # Apply custom formatter\n",
    "            for text in heatmap.texts:\n",
    "                text_value = float(text.get_text().replace('−', '-'))\n",
    "                text.set_text(custom_fmt(text_value))\n",
    "            plt.title(f'Correlation Difference: {method_name}\\nMean: {diff_results[\"mean_abs_diff\"]:.4f}, Max: {diff_results[\"max_abs_diff\"]:.4f}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"../data/figures/{method_name}_diff_heatmap.pdf\", dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {method_name}: {str(e)}\")\n",
    "    \n",
    "    # Save correlation difference metrics to CSV\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Method': list(results.keys()),\n",
    "        'Mean_Absolute_Difference': [results[method]['mean_abs_diff'] for method in results],\n",
    "        'Max_Absolute_Difference': [results[method]['max_abs_diff'] for method in results]\n",
    "    })\n",
    "    \n",
    "    metrics_df.to_csv(\"../data/correlation_difference_metrics.csv\", index=False)\n",
    "    print(\"\\nCorrelation difference metrics saved to 'correlation_difference_metrics.csv'\")\n",
    "    \n",
    "    # Find the best method\n",
    "    if results:\n",
    "        best_method = min(results.items(), key=lambda x: x[1]['mean_abs_diff'])[0]\n",
    "        print(f\"\\nBest method based on correlation preservation: {best_method}\")\n",
    "        \n",
    "        # Plot feature distributions for the best method\n",
    "        if best_method in augmented_dfs:\n",
    "            plot_feature_distributions(df, augmented_dfs[best_method], best_method)\n",
    "            print(f\"Feature distribution plot saved for {best_method}\")\n",
    "            \n",
    "            # Save the best augmented dataset to CSV\n",
    "            best_df = augmented_dfs[best_method]\n",
    "            best_df.to_csv(\"../data/features/augmented_feature_matrix.csv\", index=False)\n",
    "            print(f\"Best augmented dataset ({best_method}) saved to 'augmented_feature_matrix.csv'\")\n",
    "    \n",
    "    return results, augmented_dfs\n",
    "\n",
    "# Run the experiment\n",
    "if __name__ == \"__main__\":\n",
    "    results, augmented_dfs = run_augmentation_experiment(\"../data/features/filtered_labeled_feature_matrix.csv\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "\n",
      "Running SMOTE_k5...\n",
      "Dataset size after initial SMOTE_k5: (604, 26)\n",
      "performance_class\n",
      "0    302\n",
      "1    302\n",
      "Name: count, dtype: int64\n",
      "Large dataset size after SMOTE_k5: (10000, 26)\n",
      "performance_class\n",
      "0    5000\n",
      "1    5000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Running BorderlineSMOTE...\n",
      "Dataset size after initial BorderlineSMOTE: (604, 26)\n",
      "performance_class\n",
      "0    302\n",
      "1    302\n",
      "Name: count, dtype: int64\n",
      "Large dataset size after BorderlineSMOTE: (10000, 26)\n",
      "performance_class\n",
      "0    5000\n",
      "1    5000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Running KMeansSMOTE...\n",
      "Dataset size after initial KMeansSMOTE: (607, 26)\n",
      "performance_class\n",
      "1    305\n",
      "0    302\n",
      "Name: count, dtype: int64\n",
      "Large dataset size after KMeansSMOTE: (10007, 26)\n",
      "performance_class\n",
      "0    5004\n",
      "1    5003\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Correlation difference metrics saved to 'correlation_difference_metrics.csv'\n",
      "\n",
      "Best method based on correlation preservation: SMOTE_k5\n",
      "Feature distribution plot saved for SMOTE_k5\n",
      "Best augmented dataset (SMOTE_k5) saved to 'augmented_feature_matrix.csv'\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
